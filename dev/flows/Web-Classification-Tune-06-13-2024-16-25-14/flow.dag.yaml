id: web_classification
name: Web Classification
inputs:
  url:
    type: string
    default: https://www.microsoft.com/en-us/store/collections/xboxseriessconsoles?icid=CNav_Xbox_Series_S
    description: url to scrape and analyze.
    is_chat_input: false
outputs:
  category:
    type: string
    reference: ${convert_to_dict.output.category}
  evidence:
    type: string
    reference: ${convert_to_dict.output.evidence}
nodes:
- name: fetch_text_content_from_url
  type: python
  source:
    type: code
    path: fetch_text_content_from_url.py
  inputs:
    url: ${inputs.url}
  use_variants: false
- name: summarize_text_content
  use_variants: true
- name: classify_with_llm
  use_variants: true
- name: debug_output
  type: python
  source:
    type: code
    path: debug_output.py
  inputs:
    input1: ${classify_with_llm.output}
  use_variants: false
- name: convert_to_dict
  type: python
  source:
    type: code
    path: convert_to_dict.py
  inputs:
    input_str: ${classify_with_llm.output}
  use_variants: false
node_variants:
  summarize_text_content:
    default_variant_id: variant_0
    variants:
      variant_0:
        node:
          name: summarize_text_content
          type: llm
          source:
            type: code
            path: summarize_text_content.jinja2
          inputs:
            model: gpt-3.5-turbo-instruct
            temperature: 0.2
            top_p: 1
            max_tokens: 128
            response_format:
              type: text
            suffix: ""
            echo: false
            best_of: 1
            text: ${fetch_text_content_from_url.output}
          provider: OpenAI
          connection: prmoptflowkeyaml
          api: completion
          module: promptflow.tools.openai
      variant_1:
        node:
          name: summarize_text_content
          type: llm
          source:
            type: code
            path: summarize_text_content__variant_1.jinja2
          inputs:
            model: gpt-3.5-turbo-instruct
            temperature: 0.2
            top_p: 1
            max_tokens: 200
            response_format:
              type: text
            suffix: ""
            echo: false
            best_of: 1
            text: ${fetch_text_content_from_url.output}
          provider: OpenAI
          connection: prmoptflowkeyaml
          api: completion
          module: promptflow.tools.openai
  classify_with_llm:
    default_variant_id: variant_0
    variants:
      variant_0:
        node:
          name: classify_with_llm
          type: llm
          source:
            type: code
            path: classify_with_llm.jinja2
          inputs:
            model: gpt-3.5-turbo-instruct
            temperature: 0.2
            top_p: 1
            max_tokens: 128
            response_format:
              type: text
            suffix: ""
            echo: false
            best_of: 1
            text_content: ${summarize_text_content.output}
            url: ${inputs.url}
          provider: OpenAI
          connection: prmoptflowkeyaml
          api: completion
          module: promptflow.tools.openai
      variant_1:
        node:
          name: classify_with_llm
          type: llm
          source:
            type: code
            path: classify_with_llm__variant_1.jinja2
          inputs:
            model: gpt-3.5-turbo-instruct
            temperature: 0
            top_p: 1
            max_tokens: 128
            response_format:
              type: text
            suffix: ""
            echo: false
            best_of: 1
            text_content: ${summarize_text_content.output}
            url: ${inputs.url}
          provider: OpenAI
          connection: prmoptflowkeyaml
          api: completion
          module: promptflow.tools.openai
      variant_2:
        node:
          name: classify_with_llm
          type: llm
          source:
            type: code
            path: classify_with_llm__variant_2.jinja2
          inputs:
            model: gpt-3.5-turbo-instruct
            temperature: 0.2
            top_p: 1
            max_tokens: 128
            response_format:
              type: text
            suffix: ""
            echo: false
            best_of: 1
            text_content: ${summarize_text_content.output}
            url: ${inputs.url}
          provider: OpenAI
          connection: prmoptflowkeyaml
          api: completion
          module: promptflow.tools.openai
environment:
  python_requirements_txt: requirements.txt
  image: mcr.microsoft.com/azureml/promptflow/promptflow-runtime:20240529.v1
